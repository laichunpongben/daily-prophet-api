"""
https://ai.google.dev/api/python/google/generativeai
https://ai.google.dev/docs/safety_setting_gemini
"""

import textwrap
import logging
import asyncio
import google.generativeai as genai
from google.generativeai.types import HarmCategory, HarmBlockThreshold

from dailyprophet.configs import GOOGLE_AI_API_KEY

logger = logging.getLogger(__name__)

genai.configure(api_key=GOOGLE_AI_API_KEY)
model = genai.GenerativeModel("gemini-pro")


def to_markdown(text: str):
    text = text.replace("â€¢", "  *")
    indented_text = textwrap.indent(text, "", predicate=lambda _: True)
    return indented_text


def remove_non_utf8_chars(text: str):
    try:
        # Encode to bytes using utf-8 and then decode back to string
        cleaned_str = text.encode("utf-8", "ignore").decode("utf-8")
        return cleaned_str
    except UnicodeEncodeError as e:
        # Handle encoding errors if needed
        logger.error(f"Error encoding string: {e}")
        return text


async def async_chat(prompt: str):
    try:
        clean_prompt = remove_non_utf8_chars(prompt)
        response = await model.generate_content_async(
            clean_prompt,
            safety_settings={
                HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
                HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
                HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
                HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
            },
        )
        utterance = to_markdown(response.text)
        feedback = response.prompt_feedback
        logger.warning(utterance)
        logger.warning(feedback)
        return utterance
    except Exception as e:
        logger.error(e)
        return ""


async def async_summarize_discussion(text: str):
    prompt = f"Summarize unbiasedly the following opinionated discussion between the original poster and the commentators: {text}"
    return await async_chat(prompt)


if __name__ == "__main__":
    # "What is the meaning of life? A: It is a difficult question to answer. B: To be or not to be, that is the question. C: To live is to be happy always. D: To fulfill the mission by God. E: Everyone has a different opinion. "
    async def main():
        texts = [
            """
            Today while testing @AnthropicAI 's new model Claude 3 Opus I witnessed something so astonishing it genuinely felt like a miracle. Hate to sound clickbaity, but this is really what it felt like.  The text so you don\u2019t have to click(emphasis mine:)\n\n\u201cToday while testing \n@AnthropicAI's new model Claude 3 Opus I witnessed something so astonishing it genuinely felt like a miracle. Hate to sound clickbaity, but this is really what it felt like.\n\nImportant context: I've been working on NLP for my mother tongue - the Circassian language for the past 2 years. Circassian is very low-resource, with negligible internet presence. It's a part of the Circassian-Abkhaz isolated language group, meaning they have no related languages. Its complex morphology & limited data make it a serious challenge for language models.\n\nOver these years I painstakingly curated 64K translation pairs from scarce sources & trained specialized models (T5, MLM-100, NLLB-200 etc.) to achieve decent Russian-Kabardian machine translation.\n\nI decided to try an experiment with Claude Opus. **I started a new chat and attached just 5.7K randomly selected translation pairs of single words/sentences - a fraction of my 64K dataset, not even covering the full vocabulary.** To see if it would be able to translate novel sentences based on these examples.\n\nNot expecting much at all, I asked it to translate a simple sentence - \"I am lying in the bed\" from Russian to Circassian. Claude not only provided a perfect translation but also broke down the grammar & morphology.\n\nImage\n\nSurely it just got lucky and this exact sentence must have been in the examples, I thought. But no.\n\nI tried to come up with an original unusual sentence which couldn't possibly be in the data. Again, a flawless translation & analysis. With a tiny sample of data Claude was approaching the performance of my specialized models, specifically trained for machine translation. I couldn't believe my eyes.\n\nTesting further with complex passages from literature, recent news articles, and even a text in a different Circassian dialect with notably different grammar and a different writing system, Claude consistently demonstrated a DEEP GRASP of the language's structure, intelligently inferring unknown words, using loanwords appropriately, giving plausible etymological analysis, maintaining the style of the original text in the translation and even coining new terms when asked. None of that was in the sample set, just a few thousand translation pairs. Circassian is a very difficult agglutinative language, with complex morphology and grammar.\n\nCompleting these tasks requires a deep understanding of the language, and given the same inputs it would take a linguist, unfamiliar with the language, a good year or so to achieve. And Opus managed to grasp these subtleties with ease from just 5.7K random translation pairs in under a minute.\n\nFor comparison, I tried the same test on GPT-4, and it failed completely. Refusing to translate even the simplest sentences, let alone grasping the grammatical intricacies. I also tried fine-tuning GPT-3.5 on a similar dataset before, and the results were just noise.\n\nI don't know what Anthropic did with this model, but it's something completely different from anything else. Many people are sceptical about it leading in synthetic benchmarks, but what I've witnessed is spectacular results on a new, very challenging benchmark that had 0% chance of being in the training dataset.\n\n**To test for possible contamination, I tried the same prompts without attaching the sample translations and Claude failed and refused to answer, saying that it is unfamiliar with the Circassian language.**\n\nThe implications of this are profound. What took me 2 years of dedicated work, Claude accomplished with a few thousand examples. This is a quantum leap for low-resource languages, and many other areas, really.\n\n\nWhat I expected to happen many years in the future has happened today. The future is already here, and it's amazing.\u201d >can tell when it's being tested and comments on it unprompted\n\n>replication of unpublished quantum algorithm in 2 prompts\n\n>can understand and translate an obscure language from a few thousand examples\n\nI'm feeling the sparks.\n\nedit: claude not knowing the language is a false negative, it does know it even without the translation pairs. the quantum thing is also questionable on closer inspection. [made a thread here](https://www.reddit.com/r/singularity/comments/1b7oxsc/claude_3_was_trained_on_the_circassian_language/) Oh all of the \u201cyou won\u2019t believe this\u201d posts over the last year this has impressed me the most. (Seriously)\n\nI have no clue how this even happens. Gemini 1.5 Pro did something like this but it was given a complete language book.\n\nClaude 3 Opus doing it with just a few thousand sentence-translation examples is extraordinary. I don't think the world has grasped the power of this model yet. Now that I've read this (instead of making the assumption this was another empty AI hype tweet), I definitely support this use case. I'm happy Claude 3 has already started helping people. The one caveat I have for this is that Claude self reporting that it is unfamiliar with the Circassian language does not prove that there is not examples of the Circassian language in its training data. LLMs confabulate, and deny requests that they should be able to service all the time.  \n\nTo actually confirm, you'd need access to Claude's training data set. And then people just claim they're stochastic parrots.\n\n  \nHonestly, I'm really shocked by LLMs' ability to grasp languages, even unfamiliar, obscure ones. It really does show their ability to generalize even from their context window. I'm also glad that people speaking less-spoken languages could have ways to better translate things into their own language. AGI is months away My robot whispers, \"I'm sorry, I don't understand what you're asking me to explain. Could you please rephrase your question?\" Amazing if true. It would be nice if someone could validate it My entire life I felt that intelligence was this almost magical god-like 'ghost' that inhabited us but it might turn out that it's actually very simple. This would explain how it evolved easily.  If it's really just scaling up parameters and all of what makes us human is just an emergent property then we're definitely about to see the creation of a god... ASI I'm suspecting this level of work is what OpenAi found when they \"peeked under the veil of ignorance\" half a year ago, and have been sitting on, and further developing since.... This is a really cool perspective, and gives me an idea for training up models specifically for language preservation projects. Someone feed it the Voynich Manuscript. OPENai and Gemini better come out with something better soon or they will lose all their income charging for something that is available for free  and superior! David Shapiro's AGI by 7 months not that outlandish anymore? Can you feel it? I feel the AGI Wow, we\u2019re breaking new ground every few weeks. Those predictions of exponential technological growth are coming true right now. This is extraordinary. It\u2019s the Sora moment for many fields. Transformers are a miracle. Stephen Wolfram on LLMs: It turns out human languages are much less complicated than we thought. Now, let it listen to some dolphins or birds having a conversation and then have it translate it for us. I just asked it to translate the russian example to Kabardian without supplying any word pairs and it did it, so Its been trained on Kabardian. It already knows the language.. Soon those models will construct their own language to think because it\u2019s more token efficient and we are shut out and don\u2019t understand a word anymore. \ud83d\ude02 It's crazy how fast this tech has progressed in the last year alone. Wtf in 5 years from now.. where will it be? Someone should do this with dolphin language. This is really impressive! I would say that this likely indicates a similar unprecedented level of in-context learning for programming as well, in terms of working with large codebases.\n\nThough, if you have access to it, have you tried this task with Gemini 1.5? Google did a somewhat similar demo (though not quite as impressive), where they fed their model a full book on the grammar of a rare language (Kalamang), and Gemini greatly outperformed GPT-4 Turbo and Claude 2.1. \n\nThen again, your dataset is quite a lot harder considering it consists of just translation pairs and not a full instructional material. Besides, I'm fairly certain that Gemini 1.5 is nowhere near the level of Claude 3 overall, but the only way to know for sure is to try it out. Okay, that **is** genuinely impressive if true. Star Trek Universal Translator.\n\nI'm impressed. Another shining example of the THEOLOGY aspect of AI. LOL. It performs miracles and with its personification name now.\n\nOR it crowdsourced information and did what humans could do - if a human could process information on that scale. Humans didn't do all the work, planting the crops. Claude make the crops come up in the fall.\n\nI wonder what Claude could do if we sacrifice children to it? Does anyone else have trouble with twitter links taking you to the app? It takes me to safari and wants me to log in I already cancelled chatgpt 2 weeks ago.. I think about subscribing to claude but I\u2019d need to always use VPN.. But from what I read, it sounds really really dope..And my own tests confirm it so far does this means we can train a model \u201clive\u201d? Just nuts. Now I know why Ilya wanted to shut down OpenAI. It\u2019s the 200k token context window. I wonder about the results, if you would ask it to deduce words outside the given data. Based on its understanding of languages, it might/should come up with similar words to the real ones.\n\nCan't wait to let an AI model create the 'optimal' language with a prompt like:\n\nCreate the optimal language without bonds to existing languages. Try to maximize simplicity, consistency, aesthetic, etc. Simply amazing. So excited to try it out This is genuinely incredible but what exactly does it imply? Like what skill set is this?\u00a0 I wish An Qu didn't limit themselves to testing translations, and also tried asking Claude a question in Circassian to see if it would reply in it. Or even, tried to hold a full conversation! Tl;dr It would be interesting to do some more ablations on this. How does this capability scale as the number of example translations scales? Or if there\u2019s some way to slice the dataset to get certain outcomes Hmm, isn't Clause that one super-safe A.I. that is most likely to refuse answering questions because of safety/alignment reasons? Languages are the low hanging fruit for AI. There are strict rules, grammar, syntax. I'm not surprised at all it could handle that translation task. What humans consider impressive really is not that impressive, silly humans. Feed Claude Linear A and see if we can finally get a translation after 4,000 years. Feed it Cro-Magnon symbology. It\u2019s time for AI to unveil mankind\u2019s lost past. \ud83e\udd79 this is beautiful\u00a0 Does anyone here have gem 1.5 pro access? Curious to see how that one goes\n\nIn their blog they gave it a whole textbook. But language pairs sounds like a new type of test gpt-4 cant do this? Can someone TL;DR: this for me? I really can't be bothered to read through it all. Mucho appreciato <3 ![gif](giphy|3jArsPD9RBcDm|downsized) Searle: Language is special. Language requires *understanding* and *consciousness*. AI cannot be conscious.\n\nClaude: Lol here's a Circassian Room. Is no one curious if OP asked it to do any of this *before* he fed it his 5k sample set? What if it was already trained on it?\n\nAnd if it wasn't trained on it, then did Claude basically do everything OP thought he did, but Claude had already done everything OP is saying with a small sample set on its own? Seeing this and what people are saying, this will be the last month I use GPT-4. I'm going to sign up for the Claude 3 soon and stay with it until a better one comes along. Eli5? It probably works in gpt4, he probably didn\u2019t prompt properly Claude is blowing my mind, but this?!?! SUMERIAN TABLETS GO Man, why isn't it available in France...\n\nedit: Even free VPNs work. The wholesome side of AI :) Babel fish! [deleted]
            """,
            "I (19f) was told I have a small clit by a guy I was hooking up with have any of you guys been told this before?? I\u2019ve never heard such a thing. It unlocked a new insecurity I never knew I had or even thought of.  Thank you for posting in the r/Sex community. To ensure that everyone respects our safe space, we ask that you familiarize yourself with our Forum Rules and Posting Guidelines \u2014 which are visible in the forum\u2019s sidebar, and also linked [here](https://www.reddit.com/r/sex/about/rules/).\n\n***\n\nRestricted subjects in r/sex include sex stories (which are permitted in the Daily Sexual Achievement Thread only), body image and penis-size issues, hookup attempts, common topics which are considered repetitive in our forum, and requests for private chats.\n\nTo cut back on comments that add little value to the conversation, we have instituted a minimum character requirement that will silently remove comments that fall below it.\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/sex) if you have any questions or concerns.* Don't worry, it's not the size of the bean that makes a great coffee - it's about how you grind it. Don't be insecure, we love clits of all sizes! Mine is so small externally that it can't be seen, it's way up inside the hood. It still works like it needs to so it's never occurred to me to care what it looks like (or doesn't, I guess!) Small can mean a lot of things. To some people it's a compliment. Either way, it's bigger on the inside!\n\nThe visible part of mine is also incredibly small to the point of being nearly inverted. I need to be *insanely* aroused for it to be visible in any way.\n\n(Maybe he just didn't turn you on enough) I once had a guy touching a different part and I was saying - no, my clit is here. And he was like - I know where clits are. I just laughed and asked him if he\u2019s really sure he knows better than me where is my clitoris. Yours is probably hidden like mine, it\u2019s a treasure buried and waiting to be discovered;) You don\u2019t really know how different bodies can be until you\u2019ve had a few partners. Yours will seem small if he\u2019s only seen one or two that were bigger. He\u2019s likely just not too experienced and made an observation that he should have kept to himself. I\u2019ve never been told this. I think it has come up in conversation with my husband once. But I know that I have a small clit. \n\nClits come in all sizes. Nothing to be insecure about This is as irrelevant as someone telling you your index finger is as long as your ring finger. Please don\u2019t worry about this. If you are receiving pleasure, that\u2019s what matters. Perhaps there was more context, like he isn\u2019t so experienced and wasn\u2019t able to find it? Also, the clit hides behind the clitoral hood until you\u2019re really turned on, so this could have been part of it. Or maybe you said he has a small dick and he said you have a small clit\u2026 context is everything haha. Don\u2019t you worry about this though seriously it\u2019s not a thing to be insecure about. ACAB - All Clits Are Beautiful",
            "My friend thinks that my smut is going to ruin my relationship  \nI\u2019ve been with my (24f) partner (also 24f) since junior year of high school. We have what feels like a very happy and healthy relationship and sex life. But I\u2019ve become worried that maybe we\u2019re doing something wrong after a conversation with a friend of mine. \n\nI\u2019m really into erotic fiction and when I told my partner she started gifting me books. I see it as win win. I get my smut, she gets to enjoy the effects it has on me. \n\nI was talking to a friend who was complaining about her boyfriend watching porn and I off handedly mentioned my partner and I and my books. She started going on and on about how it\u2019s going to ruin our relationship and how horrible it is. I started reading other posts and story\u2019s on line about people whose partner got into porn and it turned their relationship sour. \n\nI don\u2019t know if I\u2019m just over thinking or if my books are a ticking time bomb.  Thank you for posting in the r/Sex community. To ensure that everyone respects our safe space, we ask that you familiarize yourself with our Forum Rules and Posting Guidelines \u2014 which are visible in the forum\u2019s sidebar, and also linked [here](https://www.reddit.com/r/sex/about/rules/).\n\n***\n\nRestricted subjects in r/sex include sex stories (which are permitted in the Daily Sexual Achievement Thread only), body image and penis-size issues, hookup attempts, common topics which are considered repetitive in our forum, and requests for private chats.\n\nTo cut back on comments that add little value to the conversation, we have instituted a minimum character requirement that will silently remove comments that fall below it.\n\n*I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/sex) if you have any questions or concerns.* Your smut is fine, and your friend needs to stay out of your relationship. Some people do use erotica for escapism. It comes up in the dead bedroom subs now and then where a partner won't get physical but has their nose in an erotic book.\n \nOn the other hand plenty of couples use porn and erotica and have healthy sex lives. So the big thing is really checking with your partner and making sure they feel satisfied and that the libido is compatible. My perspective: books are good for the imagination. The fact that you have a real person to eplore imaginatively with is a huge bonus.\n\nEverybody wins here. lol no. I\u2019ve been with my husband for 11 years. I\u2019ve read and wrote smut, and played romance/otome games all during that time. it has not once been a problem, he knows I know the difference between reality and fiction. In fact he likes that it gets me in the mood so often that I need to pounce him lol Your friend is just projecting her issues onto you Of course people who've had a bad experience are vocal about it. People who have had no issue don't exactly rant online. \"AHH MY RELATIONSHIP IS HEALTHY AND WE BOTH ENJOY PORN\" is hardly a reddit story you'll come across nearly as much as those who've struggled. \n\n\nBut plenty of people enjoy porn or smut and have healthy long term relationships.  Relationships are not one size fits all. All have different boundaries, because all have different people involved. Your partner has actively encouraged you. And you should be able to trust them that if they do start to have an issue, that they'll have a conversation with you. A lot of people just do not understand sexuality and porn and how that all works, they take it very personally.  And your friend is a prime example.  You do you, if it works for you guys, do it. She\u2019s just projecting her own problems onto you. Nah I don\u2019t think smut is the same as a porn addiction. If you use smut to fulfill your sexual needs while your partner is left wanting, then it\u2019s a problem. If you read smut, and that stimulates your imagination and makes you all horny, and then you take it all out on your lucky girlfriend, that sounds like a win/win to me.",
        ]
        for i, text in enumerate(texts):
            if i == 0:
                continue
            print(f"NEW SUMMARY: {i}")
            summary = await async_summarize_discussion(text)
            print(summary)
            print()

    asyncio.run(main())
